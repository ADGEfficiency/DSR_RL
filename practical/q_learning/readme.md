from gym import envs
print(envs.registry.all())


need to clone gym and setup.py install!!!! to get act_space.shape to work

One of the challenges with doing a reinforcement learning practical is the :


Plan = a human grid search
- everyone gets a hyper parameter to tune
learning rate, network structure, target net update freq, epsilon decay,

You will all work on different parts of the project, different bits of the code

Plan = a human grid search
- everyone gets a hyper parameter to tune
learning rate, network structure, target net update freq, epsilon decay,
can also experiment with different environments
You will all work on different parts of the project, different bits of the code. 

Would also be nice to get some practice with git

In a way this is simulating how you would understanding an open soruce project 

Also looking for someone to work on the target network update

Also tis is what I've spent a massive amount of time doing since DSR
(ie gym,tensorforce_
