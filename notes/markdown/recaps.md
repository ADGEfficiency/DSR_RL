### Recap

Three sources of generalization error
- ?
- ?
- ?

Missing relevant patterns in data = ?

Seeing patterns that aren't there = ? 

One advantage & disadvantage of lookup tables
- advantage = ?
- disadvantage = ? 

iid = ? and ? distributed 

Larger batches -> ? learning rate

Why do we pass in `None` for the first dimension in TensorFlow
`tf.placeholder(shape=(None, 14, 2))`

### Recap answers

Three sources of generalization error
- bias
- variance
- noise

Missing relevant patterns in data = bias

Seeing patterns that aren't there = variance 

One advantage & disadvantage of lookup tables
- advantage = stability
- disadvantage = no aliasing between states, curse of dimensionality

iid = independent and identically distributed 

Larger batches -> larger learning rate
- better estimation of the gradient

Why do we pass in `None` for the first dimension in TensorFlow
`tf.placeholder(shape=(None, 14, 2))`

- first dimension is the batch dimension




---
### Recap

How does reinforcement learning break iid?
- ? 
- ? 

What is the credit assignment problem?
- ? 

An MDP is composed of two objects & three signals - what are they?
- ? 
- ? 

What is off-policy learning?
- ?

Why do we discount future rewards?
- ?
- ?

---
### Recap

How does reinforcement learning break iid?
- we don't sample experience independently - sampling biased by the agent & environment
- our experience is not independent - based on trajectory in the MDP

What is the credit assignment problem?
- working out which action gave us which rewards

An MDP is composed of two objects & three signals - what are they?
- agent & environment
- state, action, reward

What is off-policy learning?
- learning from experience generated by other policies

Why do we discount future rewards?
- makes return a geometric series
- discounting is common in decision making

