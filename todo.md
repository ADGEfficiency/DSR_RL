PPO - add in to policy gradients section

## todos on the conversion

examples for everything

rewrite all algorithms into pseudo code

all of my ML notes should go into here


for PG section
- TRPO, PPO, DDPG, ACKTR, A3C etc

- MCTS 
- alpha beta search - [wiki](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning)

---

separate out literature into

value function based

policy gradient based etc
